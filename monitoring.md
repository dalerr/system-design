# Мониторинг и наблюдаемость

## Определение

**Мониторинг и наблюдаемость (Observability)** — это способность понимать внутреннее состояние системы на основе внешних данных (метрики, логи, трейсы).

В отличие от мониторинга, который предполагает знание того, что нужно отслеживать, наблюдаемость позволяет исследовать систему и находить неизвестные проблемы.

---

## Три столпа наблюдаемости

### 1. Метрики (Metrics)

**Определение:**
Числовые значения, измеряемые во времени, представляющие состояние системы или бизнес-процессов.

**Характеристики:**
- Агрегированные данные (среднее, сумма, количество)
- Используются для алертинга и визуализации
- Эффективны для хранения (меньше места, чем логи)

**Типы метрик:**

#### Инфраструктурные метрики

**CPU utilization (загрузка процессора):**
- Процент использования CPU
- Критично для производительности
- Алерт при > 80% в течение длительного времени

**Memory usage (использование памяти):**
- Процент использования RAM
- Важно для предотвращения OOM (Out of Memory)
- Алерт при > 90%

**Disk I/O (операции с диском):**
- Скорость чтения/записи
- Процент использования диска
- Алерт при > 80% заполнения

**Network traffic (сетевой трафик):**
- Входящий/исходящий трафик
- Пропускная способность
- Количество соединений

#### Метрики приложения

**Request rate (RPS — запросов в секунду):**
- Количество запросов в единицу времени
- Показывает нагрузку на систему
- Важно для capacity planning

**Latency (задержка):**
- p50 (медиана) — 50% запросов быстрее
- p95 — 95% запросов быстрее
- p99 — 99% запросов быстрее
- p99.9 — 99.9% запросов быстрее

**Error rate (процент ошибок):**
- Количество ошибок / общее количество запросов
- Критично для качества сервиса
- Алерт при > 1%

**Throughput (пропускная способность):**
- Количество успешно обработанных запросов
- Показывает производительность системы

#### Бизнес-метрики

**Количество пользователей:**
- DAU (Daily Active Users)
- MAU (Monthly Active Users)
- Новые пользователи

**Количество транзакций:**
- Успешные транзакции
- Неуспешные транзакции
- Объем транзакций

**Конверсия:**
- Процент конверсии
- Воронка конверсии

**Доход:**
- Общий доход
- Доход на пользователя
- Тренды дохода

**Примеры метрик:**
```
cpu_usage: 75%
memory_usage: 60%
request_rate: 1000 req/s
latency_p95: 150ms
error_rate: 0.1%
active_users: 50000
```

**Инструменты для метрик:**
- Prometheus
- Datadog
- CloudWatch (AWS)
- New Relic
- Grafana (визуализация)

---

### 2. Логи (Logs)

**Определение:**
Записи событий в системе, содержащие информацию о том, что произошло и когда.

**Характеристики:**
- Текстовые или структурированные (JSON)
- Используются для дебага и аудита
- Содержат детальную информацию

**Уровни логов:**

**DEBUG:**
- Детальная информация для отладки
- Обычно не включается в production
- Помогает понять детали выполнения

**INFO:**
- Общая информация о работе системы
- Важные события (запросы, ответы)
- Нормальная работа системы

**WARN:**
- Предупреждения о потенциальных проблемах
- Система работает, но что-то необычно
- Требует внимания, но не критично

**ERROR:**
- Ошибки, которые не останавливают работу
- Обработанные исключения
- Требует исправления

**FATAL:**
- Критические ошибки, останавливающие систему
- Немедленное внимание требуется
- Система не может продолжать работу

**Структурированное логирование:**

Вместо текстовых логов используйте структурированные (JSON) для лучшей обработки:

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "ERROR",
  "service": "payment-service",
  "request_id": "abc123",
  "user_id": "user456",
  "message": "Payment failed",
  "error": "Insufficient funds",
  "stack_trace": "...",
  "context": {
    "amount": 100,
    "currency": "USD"
  }
}
```

**Преимущества структурированных логов:**
- ✅ Легче парсить и анализировать
- ✅ Можно фильтровать и искать
- ✅ Автоматическая обработка
- ✅ Интеграция с системами мониторинга

**Best practices логирования:**

1. **Используйте структурированные логи (JSON)**
   - Легче обрабатывать
   - Можно автоматически парсить

2. **Включайте correlation IDs**
   - Уникальный ID для каждого запроса
   - Позволяет отследить запрос через все сервисы
   - Критично для distributed systems

3. **Не логируйте чувствительные данные**
   - Пароли, токены, номера карт
   - Персональные данные (GDPR)
   - Используйте маскирование

4. **Используйте правильные уровни логов**
   - DEBUG для отладки
   - INFO для нормальной работы
   - ERROR для ошибок
   - Не злоупотребляйте уровнями

5. **Ротируйте логи**
   - Управление размером
   - Архивация старых логов
   - Удаление через определенное время

6. **Включайте контекст**
   - Request ID
   - User ID
   - Timestamp
   - Service name

**Инструменты для логов:**
- ELK Stack (Elasticsearch, Logstash, Kibana)
- Splunk
- Datadog
- CloudWatch Logs
- Loki (Grafana)

---

### 3. Трейсинг (Distributed Tracing)

**Определение:**
Отслеживание запроса через всю распределенную систему, показывающее путь запроса через все сервисы.

**Зачем нужен:**
- Понимание flow запроса через микросервисы
- Поиск узких мест (bottlenecks)
- Отладка проблем в distributed systems
- Анализ производительности

**Концепции трейсинга:**

**Trace (трейс):**
- Полный путь запроса через систему
- Содержит все spans
- Имеет уникальный trace ID

**Span (спан):**
- Отдельная операция в трейсе
- Представляет один шаг обработки
- Имеет начало и конец
- Содержит метаданные (tags, logs)

**Parent-Child relationships:**
- Связи между спанами
- Показывают иерархию операций
- Помогают понять flow

**Пример трейса:**
```
Trace: abc123
├─ Span: API Gateway (10ms)
│  ├─ Span: Auth Service (5ms)
│  └─ Span: Payment Service (200ms)
│     ├─ Span: Database Query (150ms)
│     └─ Span: External API Call (30ms)
```

**Информация в span:**
- Operation name
- Start time и duration
- Tags (метаданные)
- Logs (события)
- Parent span ID

**Инструменты трейсинга:**
- OpenTelemetry (стандарт)
- Jaeger
- Zipkin
- AWS X-Ray
- Datadog APM
- New Relic

**Best practices трейсинга:**
- ✅ Используйте OpenTelemetry для стандартизации
- ✅ Включайте correlation IDs
- ✅ Трейсируйте все внешние вызовы
- ✅ Не трейсируйте внутренние операции (слишком детально)
- ✅ Используйте sampling для снижения нагрузки

---

## Мониторинг для разных ролей

### Мониторинг для Backend

**Метрики серверов:**
- CPU utilization
- Memory usage
- Disk I/O
- Network traffic

**Метрики БД:**
- Query time
- Connections pool
- Replication lag
- Cache hit rate
- Slow queries

**Метрики API:**
- Request rate (RPS)
- Latency (p50, p95, p99)
- Error rate
- Throughput

**Метрики очередей:**
- Queue depth
- Processing time
- Message rate
- Dead letter queue size

**Health checks сервисов:**
- Liveness probe
- Readiness probe
- Dependency health

---

### Мониторинг для Frontend

**Метрики производительности:**
- Page load time
- First Contentful Paint (FCP)
- Largest Contentful Paint (LCP)
- Time to Interactive (TTI)
- Cumulative Layout Shift (CLS)

**Метрики ошибок:**
- JavaScript errors
- API errors
- Resource loading errors
- Network errors

**Метрики пользователей:**
- Bounce rate
- Session duration
- Page views
- User actions

**Real User Monitoring (RUM):**
- Мониторинг реальных пользователей
- Производительность в реальных условиях
- Географическое распределение

**Synthetic monitoring:**
- Автоматические тесты
- Проверка доступности
- Проверка производительности

**Инструменты:**
- Google Analytics
- Sentry
- Datadog RUM
- New Relic Browser
- CloudWatch RUM

---

## Алертинг

**Определение:**
Автоматическое уведомление о проблемах в системе на основе метрик и логов.

**Принципы алертинга:**

1. **Настройка правильных порогов**
   - Не слишком чувствительные (шум)
   - Не слишком слабые (пропуск проблем)
   - Учитывайте нормальные колебания

2. **Runbooks для реагирования**
   - Документация действий при алерте
   - Пошаговые инструкции
   - Эскалация при необходимости

3. **Приоритизация алертов**
   - Critical — немедленное внимание
   - Warning — требует внимания
   - Info — для информации

4. **Группировка алертов**
   - Избегайте алерт-шторма
   - Группируйте связанные алерты
   - Используйте suppression

**Примеры алертов:**

**Критичные:**
- CPU > 80% в течение 5 минут
- Error rate > 1% в течение 1 минуты
- Latency p95 > 500ms в течение 5 минут
- Service unavailable
- Disk space < 10%

**Предупреждения:**
- CPU > 70% в течение 10 минут
- Error rate > 0.5% в течение 5 минут
- Latency p95 > 300ms в течение 10 минут
- Queue depth > 1000

**Информационные:**
- Новый релиз развернут
- Необычный паттерн трафика
- Изменения в метриках

**Инструменты алертинга:**
- Prometheus Alertmanager
- PagerDuty
- Opsgenie
- Datadog Alerts
- CloudWatch Alarms

---

## Инструменты мониторинга

### Метрики
- **Prometheus** — open-source, pull-based
- **Datadog** — SaaS, comprehensive
- **CloudWatch** — AWS native
- **New Relic** — SaaS, APM focus
- **Grafana** — визуализация

### Логи
- **ELK Stack** — Elasticsearch, Logstash, Kibana
- **Splunk** — enterprise solution
- **Datadog** — unified platform
- **CloudWatch Logs** — AWS native
- **Loki** — Grafana native

### Трейсинг
- **OpenTelemetry** — стандарт, vendor-neutral
- **Jaeger** — open-source
- **Zipkin** — open-source
- **AWS X-Ray** — AWS native
- **Datadog APM** — SaaS

### Dashboards
- **Grafana** — популярный, гибкий
- **Datadog** — integrated dashboards
- **CloudWatch Dashboards** — AWS native
- **Kibana** — для ELK Stack

---

## Стратегия мониторинга

### Что мониторить

1. **Инфраструктура**
   - Серверы (CPU, memory, disk)
   - Сеть (traffic, latency)
   - Базы данных

2. **Приложение**
   - Request rate
   - Latency
   - Error rate
   - Throughput

3. **Бизнес-метрики**
   - Пользователи
   - Транзакции
   - Конверсия
   - Доход

4. **Зависимости**
   - Внешние API
   - Базы данных
   - Очереди
   - Кеши

### Как мониторить

1. **Метрики для алертинга**
   - Критичные метрики
   - Пороги для алертов
   - Runbooks

2. **Логи для дебага**
   - Структурированные логи
   - Correlation IDs
   - Централизованное хранение

3. **Трейсинг для анализа**
   - Distributed tracing
   - Performance analysis
   - Bottleneck identification

---

## Резюме

**Ключевые принципы:**

1. ✅ **Используйте три столпа** — метрики, логи, трейсинг
2. ✅ **Структурируйте данные** — JSON логи, стандартные метрики
3. ✅ **Настройте алертинг** — правильные пороги, runbooks
4. ✅ **Визуализируйте** — dashboards для понимания
5. ✅ **Мониторьте все уровни** — инфраструктура, приложение, бизнес
6. ✅ **Используйте correlation IDs** — для трейсинга запросов

**Помните:** Хороший мониторинг позволяет быстро находить и решать проблемы. Плохой мониторинг приводит к слепоте и долгому времени восстановления.

